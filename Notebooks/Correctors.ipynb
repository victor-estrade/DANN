{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "from __future__ import division, print_function\n",
    "\n",
    "import sys, os\n",
    "sys.path.append('..')\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "!pip install seaborn;\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "from logs import log_fname, new_logger\n",
    "from nn.rgl import ReverseGradientLayer\n",
    "from nn.block import Dense, Classifier\n",
    "from nn.compilers import crossentropy_sgd_mom, squared_error_sgd_mom\n",
    "from nn.training import Trainner, training\n",
    "\n",
    "from utils import plot_bound, save_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load datasets\n",
    "\n",
    "Here the datasets are loaded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clouds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clouds rotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datasets.toys import load_cloud_rotated\n",
    "\n",
    "\n",
    "data_name = 'Clouds_Rotated'\n",
    "n_samples = 30  # Number of sample per class\n",
    "n_classes = 12\n",
    "batchsize = 80\n",
    "angle = 80\n",
    "\n",
    "source_data, target_data, domain_data = load_cloud_rotated(n_sample=n_samples, \n",
    "                                                           n_classes=n_classes, \n",
    "                                                           angle=angle, \n",
    "                                                           batchsize=batchsize)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clouds . Random Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datasets.toys import load_cloud_rotated\n",
    "from datasets.utils import random_mat_dataset\n",
    "\n",
    "\n",
    "data_name = 'Clouds_RMat'\n",
    "n_samples = 30  # Number of sample per class\n",
    "n_classes = 12\n",
    "batchsize = 80\n",
    "angle = 80\n",
    "\n",
    "source_data, target_data, domain_data = load_cloud_rotated(n_sample=n_samples, \n",
    "                                                           n_classes=n_classes, \n",
    "                                                           angle=angle, \n",
    "                                                           batchsize=batchsize)\n",
    "source_data, target_data, domain_data = random_mat_dataset(source_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moon rotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datasets.toys import load_moon\n",
    "\n",
    "data_name = 'Moon_Rotated'\n",
    "n_samples = 800\n",
    "batchsize = 80\n",
    "angle = 30.\n",
    "\n",
    "source_data, target_data, domain_data = load_moon(n_samples=n_samples, angle=angle, batchsize=batchsize)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moon . Random Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datasets.toys import load_moon\n",
    "from datasets.utils import random_mat_dataset\n",
    "\n",
    "data_name = 'Moon_RMat'\n",
    "n_samples = 800\n",
    "batchsize = 80\n",
    "angle = 30.\n",
    "\n",
    "source_data, target_data, domain_data = load_moon(n_samples=n_samples, angle=angle, batchsize=batchsize)\n",
    "source_data, target_data, domain_data = random_mat_dataset(source_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST . Diag Dominant matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datasets.mnist import load_mnist_src\n",
    "from datasets.utils import diag_dataset\n",
    "\n",
    "data_name = 'MNIST_Diag'\n",
    "batchsize = 500\n",
    "\n",
    "source_data = load_mnist_src(batchsize=batchsize)\n",
    "source_data, target_data, domain_data = diag_dataset(source_data, normalize=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST Mirror"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datasets.mnist import load_mnist_mirror\n",
    "\n",
    "data_name = 'MNIST_Mirror'\n",
    "batchsize = 500\n",
    "\n",
    "source_data, target_data, domain_data = load_mnist_mirror(batchsize=batchsize)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST . Random Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datasets.mnist import load_mnist_src\n",
    "from datasets.utils import random_mat_dataset\n",
    "\n",
    "data_name = 'MNIST_Rmat'\n",
    "batchsize = 500\n",
    "\n",
    "source_data = load_mnist_src(batchsize=batchsize)\n",
    "source_data, target_data, domain_data = random_mat_dataset(source_data, normalize=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the *corrector* and *domain* dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "domain_data = {\n",
    "            'X_train': [source_data['X_train'], target_data['X_train']],\n",
    "            'X_val': [source_data['X_val'], target_data['X_val']],\n",
    "            'X_test': [source_data['X_test'], target_data['X_test']],\n",
    "            'y_train': None,\n",
    "            'y_val': None,\n",
    "            'y_test': None,\n",
    "            'batchsize': batchsize,\n",
    "            }    \n",
    "\n",
    "corrector_data = dict(target_data)\n",
    "corrector_data.update({\n",
    "    'y_train': source_data['X_train'],\n",
    "    'y_val': source_data['X_val'],\n",
    "    'y_test': source_data['X_test'],\n",
    "    'labels': source_data['y_train'],\n",
    "    'batchsize': batchsize,\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get a logger\n",
    "logger = new_logger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "hp_lambda = 0.0\n",
    "\n",
    "label_rate = 1\n",
    "label_mom = 0.9\n",
    "\n",
    "domain_rate = 1\n",
    "domain_mom = 0.9\n",
    "\n",
    "k = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epoch Preprocessing\n",
    "\n",
    "The preprocessing function that will run at the begining of each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# http://stackoverflow.com/questions/25886374/pdist-for-theano-tensor\n",
    "# Tested and approved\n",
    "X = T.fmatrix('X')\n",
    "Y = T.fmatrix('Y')\n",
    "translation_vectors = X.reshape((X.shape[0], 1, -1)) - Y.reshape((1, Y.shape[0], -1))\n",
    "euclidiean_distances = (translation_vectors ** 2).sum(2)\n",
    "f_euclidean = theano.function([X, Y], euclidiean_distances, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kclosest(X, Y, k, batchsize=None):\n",
    "    \"\"\"\n",
    "    Computes for each sample from X the k-closest samples in Y and return \n",
    "    their index.\n",
    "\n",
    "    Params\n",
    "    ------\n",
    "        X: (numpy array [n_sample, n_feature])\n",
    "        Y: (numpy array [n_sample, n_feature])\n",
    "        k: (int)\n",
    "    Return\n",
    "    ------\n",
    "        kclosest : (numpy array [n_sample, k]) the ordered index of \n",
    "            the k-closest instances from Y to X samples\n",
    "    \"\"\"\n",
    "    assert X.shape == Y.shape\n",
    "    N = X.shape[0]\n",
    "    if batchsize is None:\n",
    "        dist = f_euclidean(X, Y)\n",
    "    else:\n",
    "        dist = np.empty((N, N), dtype=theano.config.floatX)\n",
    "        batch = np.arange(0, N+batchsize, batchsize)\n",
    "        for excerpt_X in (slice(i0, i1) for i0, i1 in zip(batch[:-1], batch[1:])):\n",
    "            dist[excerpt_X] = f_euclidean(X[excerpt_X], Y)\n",
    "    kbest = np.argsort(dist, axis=1)[:, :k]\n",
    "    return kbest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def realign(X_out, X_trg, y, k=20, batchsize=None):\n",
    "    counter = np.zeros(X_out.shape[0], dtype=int)\n",
    "    idx = np.empty_like(y, dtype=int)\n",
    "    for label in np.unique(y):\n",
    "        # Get the examples of the right label\n",
    "        idx_label = np.where(y==label)[0]\n",
    "\n",
    "        # Get the k-closest index ... shape = ... ça va pas du tout !\n",
    "        idx_label2 = kclosest(X_out[idx_label], X_trg[idx_label], k, batchsize=batchsize)\n",
    "        \n",
    "        for i1, i2 in zip(idx_label, idx_label2):\n",
    "            # i2 is an index array of shape (k,) with the sorted closest example index \n",
    "            # (of the sorted single class array)\n",
    "            # Then idx_label[i2] are the sorted original index of the k-closest examples\n",
    "            i = idx_label[i2[np.argmin(counter[idx_label[i2]])]]\n",
    "            # i contains the chosen one, in the (k-)clostest example, with the minimum counter\n",
    "            counter[i] = counter[i]+1\n",
    "            idx[i1] = i\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batchpad(batchsize, output_shape, dtype=None):\n",
    "    \"\"\"Re-batching decorator\n",
    "    \"\"\"\n",
    "    def decoreted(func):\n",
    "        def wrapper(X, *args, **kwargs):\n",
    "            if dtype is None:\n",
    "                dtype2 = X.dtype\n",
    "            else:\n",
    "                dtype2 = dtype\n",
    "            \n",
    "            N = X.shape[0]\n",
    "            \n",
    "            if output_shape is None:\n",
    "                shape = X.shape\n",
    "            else:\n",
    "                shape = tuple( out_s if out_s is not None else X_s for out_s, X_s in zip(output_shape, X.shape))\n",
    "\n",
    "            result = np.empty(shape, dtype=dtype2)\n",
    "            batch = np.arange(0, N+batchsize, batchsize)\n",
    "            for excerpt_X in (slice(i0, i1) for i0, i1 in zip(batch[:-2], batch[1:])):\n",
    "                result[excerpt_X] = func(X[excerpt_X], *args, **kwargs)\n",
    "            \n",
    "            last_excerpt = slice(batch[-2], batch[-1])\n",
    "            X = X[last_excerpt]\n",
    "            n_sample = X.shape[0]\n",
    "            X = np.vstack([X, np.zeros((batchsize-X.shape[0],)+X.shape[1:])])\n",
    "            X = func(X, *args, **kwargs)\n",
    "            result[last_excerpt] = X[:n_sample]\n",
    "            \n",
    "            return result\n",
    "        return wrapper\n",
    "    return decoreted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocess(data, trainer, epoch):\n",
    "    X = data['X_train']\n",
    "\n",
    "    @batchpad(data['batchsize'], X.shape, X.dtype)\n",
    "    def f_output(X, trainer):\n",
    "        return trainer.output(X)[0]\n",
    "    \n",
    "    X_out = f_output(X, trainer)\n",
    "    X_trg = data['y_train']\n",
    "    data['X_train'] = X[realign(X_out, X_trg, data['labels'], k=5, batchsize=None)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classwise_shuffle(X, y):\n",
    "    \"\"\"\n",
    "    Shuffle X without changing the class positions\n",
    "\n",
    "    Params\n",
    "    ------\n",
    "        X: the data (numpy array)\n",
    "        y: the labels \n",
    "    Return\n",
    "    ------\n",
    "        X_shuffled: Shuffled X without changing the class matching\n",
    "    \"\"\"\n",
    "    idx = np.empty_like(y, dtype=int)\n",
    "    for label in np.unique(y):\n",
    "        arr = np.where(y==label)[0]\n",
    "        arr2 = np.random.permutation(arr)\n",
    "        idx[arr] = arr2\n",
    "    return X[idx]\n",
    "\n",
    "\n",
    "def epoch_shuffle(data, trainer, epoch, *args, **kwargs):\n",
    "    data['X_train'] = classwise_shuffle(data['X_train'], data['labels'])\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network building\n",
    "Start with the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prepare Theano variables for inputs and targets\n",
    "if data_name.startswith('MNIST'):\n",
    "    input_var = T.tensor3('inputs')\n",
    "    src_var = T.tensor3('src')\n",
    "    target_var = T.tensor3('targets')\n",
    "    shape = (batchsize, 28, 28)\n",
    "elif data_name.startswith('Moon') or data_name.startswith('Clouds'):\n",
    "    input_var = T.matrix('inputs')\n",
    "    src_var = T.matrix('src')\n",
    "    target_var = T.matrix('targets')\n",
    "    shape = (batchsize, 2)\n",
    "\n",
    "# Logs\n",
    "logger.info('Building the input and output variables for |{}|'.format(data_name))\n",
    "logger.info('Input data expected shape : {}'.format(shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the neual network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build the layers\n",
    "input_layer = lasagne.layers.InputLayer(shape=shape, input_var=input_var)\n",
    "src_layer = lasagne.layers.InputLayer(shape=shape, input_var=src_var)\n",
    "# feature = lasagne.layers.DenseLayer(\n",
    "#                 input_layer,\n",
    "#                 num_units=np.prod(shape[1:]),\n",
    "#                 nonlinearity=lasagne.nonlinearities.tanh,\n",
    "#                 # W=lasagne.init.Uniform(range=0.01, std=None, mean=0.0),\n",
    "#                 )\n",
    "feature = lasagne.layers.DenseLayer(\n",
    "                input_layer,\n",
    "                num_units=np.prod(shape[1:]),\n",
    "                nonlinearity=None,\n",
    "                # W=lasagne.init.Uniform(range=0.01, std=None, mean=0.0),\n",
    "                )\n",
    "reshaper = lasagne.layers.ReshapeLayer(feature, (-1,) + shape[1:])\n",
    "output_layer = reshaper\n",
    "\n",
    "# Logs\n",
    "logger.info('Building the neural network architecture for |{}|'.format(data_name))\n",
    "logger.info('Input data expected shape : {}'.format(shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Logs\n",
    "logger.info('Compiling the neural network for |{}|'.format(data_name))\n",
    "logger.info('Input data expected shape : {}'.format(shape))\n",
    "\n",
    "# Compilation\n",
    "corrector_trainner = Trainner(squared_error_sgd_mom(output_layer, lr=label_rate, mom=0, target_var=target_var), \n",
    "                             'corrector',)\n",
    "\n",
    "if hp_lambda != 0.0:\n",
    "    print('hp_lambda != 0 : Compliling the adversarial part of the networks')\n",
    "    domain_trainner = Trainner(adversarial([src_layer, output_layer], hp_lambda=hp_lambda,\n",
    "                                          lr=domain_rate, mom=domain_mom),\n",
    "                               'domain')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add preprocessing (for alignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add preprocessing :\n",
    "corrector_trainner.preprocess = epoch_shuffle\n",
    "#corrector_trainner.preprocess = preprocess\n",
    "\n",
    "#model_name = 'Pairwise_Corrector'\n",
    "model_name = 'Classwise_Corrector'\n",
    "#model_name = 'K-closest_Corrector'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Train the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset the counter and the stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logger.warn('Reset the epoch counter and saved statistics')\n",
    "epoch_counter = 0\n",
    "final_stats = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_epoch = 1\n",
    "epoch_counter += n_epoch\n",
    "logger.info('Trainning the neural network for {} additional epochs ({} total)'.format(n_epoch, epoch_counter))\n",
    "if hp_lambda != 0.0:\n",
    "    stats = training([corrector_trainner, domain_trainner], [corrector_data, domain_data],\n",
    "                     num_epochs=n_epoch, logger=logger)\n",
    "else:\n",
    "    stats = training([corrector_trainner,], [corrector_data,],\n",
    "                 num_epochs=n_epoch, logger=logger)\n",
    "\n",
    "final_stats = {k: (final_stats[k]+v if k in final_stats else v) for k, v in stats.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "title = '++'.join([data_name, model_name, 'lambda={:.3e}'.format(hp_lambda)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Learning curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot learning accuracy curve\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(final_stats['corrector valid loss'], label='source')\n",
    "ax.set_xlabel('epoch')\n",
    "ax.set_ylabel('loss')\n",
    "ax.set_title(title)\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles, labels, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "#fig.savefig('fig/'+title+'.png', bbox_inches='tight')\n",
    "#fig.clf() # Clear plot window\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Data plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.cm as cm\n",
    "cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "if data_name.startswith('Moon'):\n",
    "    color = cm.ScalarMappable(cmap=cm_bright)\n",
    "else:\n",
    "    color = cm.ScalarMappable(cmap='Paired')\n",
    "\n",
    "if data_name.startswith('Moon') or data_name.startswith('Clouds'):\n",
    "    # Plot the test data\n",
    "    fig, ax = plt.subplots()\n",
    "    X = source_data['X_test']\n",
    "    y = source_data['y_test']\n",
    "    ax.scatter(X[:, 0], X[:, 1], label='source', marker='o', s=80, edgecolors=color.to_rgba(y), facecolors='none')\n",
    "\n",
    "    X = np.array(corrector_trainner.output(target_data['X_test'])).reshape((-1, 2))\n",
    "    y = target_data['y_test']\n",
    "    ax.scatter(X[:, 0], X[:, 1], label='corrected', marker='x', s=80, edgecolors=color.to_rgba(y), facecolors=color.to_rgba(y))\n",
    "    ax.set_title(title)\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.legend(handles, labels, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    #fig.savefig('fig/'+title+'-corrected_data.png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    logger.info('Data plot {}'.format(X.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code concatenation !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_epoch = 10\n",
    "epoch_counter += n_epoch\n",
    "logger.info('Trainning the neural network for {} additional epochs ({} total)'.format(n_epoch, epoch_counter))\n",
    "if hp_lambda != 0.0:\n",
    "    stats = training([corrector_trainner, domain_trainner], [corrector_data, domain_data],\n",
    "                     num_epochs=n_epoch, logger=logger)\n",
    "else:\n",
    "    stats = training([corrector_trainner,], [corrector_data,],\n",
    "                 num_epochs=n_epoch, logger=logger)\n",
    "\n",
    "final_stats = {k: (final_stats[k]+v if k in final_stats else v) for k, v in stats.items()}\n",
    "\n",
    "# -----\n",
    "title = '++'.join([data_name, model_name, 'lambda={:.3e}'.format(hp_lambda)])\n",
    "# Plot learning accuracy curve\n",
    "fig, (ax, ax1) = plt.subplots(1, 2, figsize=(20,10))\n",
    "ax.plot(final_stats['corrector valid loss'], label='source')\n",
    "ax.set_xlabel('epoch')\n",
    "ax.set_ylabel('loss')\n",
    "ax.set_title(title)\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles, labels, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "#fig.savefig('fig/'+title+'.png', bbox_inches='tight')\n",
    "#fig.clf() # Clear plot window\n",
    "#plt.show()\n",
    "\n",
    "# -----\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.cm as cm\n",
    "cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "if data_name.startswith('Moon'):\n",
    "    color = cm.ScalarMappable(cmap=cm_bright)\n",
    "else:\n",
    "    color = cm.ScalarMappable(cmap='Paired')\n",
    "\n",
    "if data_name.startswith('Moon') or data_name.startswith('Clouds'):\n",
    "    # Plot the test data\n",
    "    #fig, ax = plt.subplots()\n",
    "    X = source_data['X_test']\n",
    "    y = source_data['y_test']\n",
    "    ax1.scatter(X[:, 0], X[:, 1], label='source', marker='o', s=80, edgecolors=color.to_rgba(y), facecolors='none')\n",
    "\n",
    "    X = np.array(corrector_trainner.output(target_data['X_test'])).reshape((-1, 2))\n",
    "    y = target_data['y_test']\n",
    "    ax1.scatter(X[:, 0], X[:, 1], label='corrected', marker='x', s=80, edgecolors=color.to_rgba(y), facecolors=color.to_rgba(y))\n",
    "    ax1.set_title(title)\n",
    "    handles, labels = ax1.get_legend_handles_labels()\n",
    "    ax1.legend(handles, labels, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    #fig.savefig('fig/'+title+'-corrected_data.png', bbox_inches='tight')\n",
    "    fig.show()\n",
    "\n",
    "    logger.info('Data plot {}'.format(X.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
